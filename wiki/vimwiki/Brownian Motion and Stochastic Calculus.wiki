= Brownian Motion and Stochastic Calculus =
== UChicago STAT 38510, Autumn 2023 ==

{{$
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}

\DeclareMathOperator{\Jac}{Jac}
\DeclareMathOperator{\Ker}{Ker}

\let\temp\phi
\let\phi\varphi
\let\varphi\temp

\newcommand{\pa}[1]{\left(#1\right)}
\newcommand{\bra}[1]{\left[#1\right]}
\newcommand{\cbra}[1]{\left\{#1\right\}}

\newcommand{\mat}[1]{\begin{matrix}#1\end{matrix}}
\newcommand{\pmat}[1]{\pa{\mat{#1}}}
\newcommand{\bmat}[1]{\bra{\mat{#1}}}

\newcommand{\pfrac}[2]{\pa{\frac{#1}{#2}}}
\newcommand{\bfrac}[2]{\bra{\frac{#1}{#2}}}
\newcommand{\psfrac}[2]{\pa{\sfrac{#1}{#2}}}
\newcommand{\bsfrac}[2]{\bra{\sfrac{#1}{#2}}}
}}$

=== Brownian Motion ===

As a style preference, I'm going to drop all the arguments that are from the probability space.

Fix a probability space $(\Omega, \mathcal F, P)$; we characterize the Brownian motion $\{B_t\}_{t \geq 0}$ via the follwing properties:
- *Independent Increments*: If $s < t$, the random variable $B_t - B_s$ is independent of $\sigma\{B_r: r \leq s\}$
- *Stationary Increments*: If $s < t$, then $B_t - B_s$ has the same distribution as $B_{t-s} - B_0$.
- *Continuity*: The map $t \mapsto B_t$ is almost surely continuous. 

*Theorem*: If a process satisfies the above, then there are $\mu, \sigma^2$ (respectively called the drift and the variance parameter, and $\sigma$ is named the volatility) such that there exist $B_t \sim N(\mu t, \sigma^2 t)$.

_Def_: A stochastic process $\{B_t\}_{t \geq 0}$ is called a (one dimensional) *Brownian motion* (or Wiener process) starting from the origin with drift $\mu$ and variance parameter $\sigma^2$ if $B_t = 0$ and the above three conditions are satisfied, with the imposition that 
{{$
B_t - B_s \sim N(\mu (t-s), \sigma^2 (t-s)).
}}$

*Prop*: If $B_t$ is a Brownian motion with $\mu = 0, \sigma^2 = 1$ (a so-called *standard Brownian motion*), then $Y_t = \sigma B_t + \mu t$ is a Brownian motion with parameters $\mu, \sigma^2$.

_Proof_: Obvious.

==== Construction ====

Pick a probability space $(\Omega, \mathcal F, P)$ that is rich enough to support a countable collection of independent standard normal variables. If you are particular, the unit interval with Lesbegue measure is sufficient here.

The strategy is as follows: we define $B_t$ for a countable dense set (in particular the dyadic rationals) of times using our precession of standard normals. then, we find some $t \mapsto B_t$ that agrees on the dense set and is uniformly continuous and then extend by continuity.

Set $D_n = \left\{ \frac{k}{2^n}, k = 0, 1, \dots, 2^n \right\}$ and $D = \bigcup_{n=0}^\infty D_n$; index our standard normals by $\{N_{q}\}_{q \in D}$, and set $B_0 = 0, B_1 = N_1$, and $B_{1/2} = \frac{B_1 - B_0}{2} + \frac{1}{2}N_{1/2}$. Just continue the same thing for every such dyadic, such that
{{$
\{B_{1/2^n} - B_0, B_{2/2^n} - B_{1/2^n}, \dots, B_1- B_{(2^n-1) / 2^n} \}
}}$
are all independent $N\left(0, 2^{-n}\right)$. 

*Theorem*: Almost surely, $t \mapsto B_t$, $t \in D$ is uniformly continuous.

_Proof_: Set $K_n = \sup \{ |B_s - B_t| \mid s,t \in D, |s - t| \leq 2^{-n}\}$. We just need to show that $K_n \to 0$ as $n \to \infty$. In fact, something even stronger is true: for $\alpha < \frac{1}{2}$, $\lim_{n \to \infty} 2^{\alpha n}K_n = 0$. Morally speaking, just think that each Brownian increment is about its standard deviation, which is $|t - s|^{1/2}$.

Technically, however, we proceed as follows: set
{{$
  Y_n = \max\{B_{1/2^n} - B_0, B_{2/2^n} - B_{1/2^n}, \dots, B_1- B_{(2^n-1) / 2^n} \}
}}$
and note that the union bound yields
{{$ 
\begin{align*}
  P(Y_n \geq x) &\leq \sum_{j=1}^{2^n} P(|B_{j/2^n} - B_{(j-1)/2^n}| \geq x) \\
      &= 2^nP(B_{1/2^n} \geq x) \\
      &= 2^{n+1}P(B_1 \geq 2^{n/2} x).
\end{align*}
}}$
If we choose $x_n$ such that $\sum_{n=1}^\infty 2^{n+1}P(B_1 \geq 2^{n/2}x_n) < \infty$, then by Borel-Cantelli shows that for sufficiently large $n$, $Y_n \leq x_n$ almost surely. Do any reasonable bound you like on the tail of the normal distribution and take a sufficiently large $x$ and call it a day. In particular, if you choose the easiest bound $P(N \geq x) \leq Ce^{-x^2/2}$, you can eventually get the bound:

*Prop*:
{{$
  \limsup_{n \to \infty} \frac{2^{n/2}}{\sqrt{n}}Y_n \leq \sqrt{2 \log 2}.
}}$

_Proof_: Look at the sum
{{$
  \sum_{n=1}^\infty P\left(Y_n > \sqrt{n} \cdot 2 ^{-n/2} \cdot \sqrt{2 \log 2 (1 + \epsilon)}\right)
}}$
and apply Borel-Cantelli. In particular, we have
{{$
\begin{align*}
  P(Y_n > x_n) &\leq \sum_{j=1^{2^n}} P(|B_{j/2^n} - B_{(j-1)/2^n}| > x_n) \\
  &= 2^{n+1}P(B_{1/2^n} > x_n) \\
  &= 2^{n+1}P\left(B_1 > \sqrt{n} \sqrt{2(\log 2 (1 + \epsilon)}\right) \\
  &\leq C 2^n e^{-\frac{\sqrt{2\log 2 n(1+\epsilon)^2}}{2}} \\
  &\leq C e^{-n\epsilon}.
\end{align*}
}}$

*Prop*: Set $K_n = \sup \{ |B_s - B_t| \mid s,t \in D, |s - t| \leq 2^{-n}\}$; then, there is $C$ such that with almost surely,
{{$
  \limsup_{n \to \infty} \frac{2^{n/2}}{\sqrt{n}}K_n \leq C.
}}$

_Proof_: It's easy to see that $K_n \leq 2 \sum_{j=n+1}^\infty Y_j$ (this is just the triangle inequality). Then for sufficiently large $n$, we get
{{$
  K_n \leq 2 \cdot 2 \sum_{j=n+1}^\infty 2^{-j/2}\sqrt{j}
}}$
with full probability, and so
{{$
  \sup_{\substack{s, t \in D \\ s < t}} \frac{|B_t - B_s|}{\sqrt{(t-s)(|\log(t-s)| + 1)}} < \infty.
}}$

Now we may set $B_t$ for $t \in [0, 1]$ by $B_t = \lim_{\substack{s \to t \\ s \in D}}B_s$, and check that this is in fact a genuine Brownian motion, which is not bad; and of course this construction can extend to $[0, \infty)$ easily as well.

==== Properties of Brownian Motion ====

_Def_: A function $f: [0, 1] -> \mathbb R$ is called *Hölder continuous* of order $\beta \geq 0$ if there is some $C < \infty$ such that for all $s, t$, $|f(t) - f(s)| \leq C|t-s|^\beta$. Futher, $f$ is *weakly Hölder continuous* of order $\beta$ if it is Hölder continuous of order $\alpha$ for all $\alpha < \beta$. In both cases, we will say Hölder-$\beta$ continuous for short.

*Prop*: Brownian motion paths are weakly Hölder-$\frac{1}{2}$ continuous.

_Proof_: Omitted.

*Theorem*: The function $t \mapsto B_t$ is nowhere differentiable almost surely.

_Proof_: Assume $|f'(t)| < K$; there exists $\delta > 0$ such that if $|s - t| \leq \delta$, $|f(t) - f(s)| \leq 2K|s-t|$; in particular there is an $N$ such that for all $n > N$, $|s - t| \leq n^{-1}, |r - t| \leq n^{-1}$, $|f(s) - f(r)| \leq 4Kn^{-1}$. Then, set 
{{$
  Z_{k, n} = \max \left\{ |B_{k/n} - B_{(k-1)/n}|, |B_{(k+1)/n} - B_{k/n}|, |B_{(k+2)/n} - B_{(k+1)/n}|\right\}
}}$
and
{{$
  Z_n = \min \{ Z_{k, n} \mid k = 1, \dots, n \}.
}}$

If $B$ is differentiable, then there is some $M$ such that $Z_n \leq Mn^{-1}$ for all $n$. Now set $E_M$ to be the event that $Z_n \leq Mn^{-1}$ for all sufficiently large; our theorem reduces to showing that $P(E_M)  = 0$ for all $M$. In fact, we will show that
{{$
  \lim_{n \to \infty} P(Z_n \leq Mn^{-1}) = 0.
}}$

Consider the union bound
{{$
\begin{align*}
  P(Z_n \leq Mn^{-1}) &\leq \sum_{j=1}^{n}P(Z(n,k) \leq Mn^{-1}) \\
  &\leq nP\left( \max \left\{ |B_{1/n}|, |B_{2/n} - B_{1/n}|, |B_{3/n} - B_{2/n}|\right\}
\right) \\
&\leq nP(|B_{1/n}| \leq Mn^{-1})^3 \\
&\leq nP(|B_1| \leq Mn^{-1/2})^3
\end{align*}
}}$
and just do literally the stupidest estimate you can, e.g. just look at the density and say that the probability is bounded by $2CMn^{-1/2}$, so that the above is sent to zero as $n \to \infty$.

_Def_: For some stochastic process $\{X_t\}_{t \geq 0}$ (or any other indexed set) with filtration $\{F_t\}_{t \geq 0}$, $X_t$ has the *Markov property* if it saitisfies that
{{$
  E[f(X_t) \mid \mathcal F_s] = E[f(X_t) \mid \sigma(X_s)].
}}$

In particular, the following is clear for Brownian motion:

*Prop*: If $\{B_t\}_{t \geq 0}$ is a BM, $t$ a fixed time, and $Y_s = B_{t+s} - B_t$, then $\{Y_s\}_{s \geq 0}$, is a BM and independent of $\mathcal F_t = \sigma\{B_s \mid s \leq t\}$.

Now set $B_t$ to a Brownian motion with drift zero and $\tau_a = \min \{ s \mid B_s = a \}$; the reflection principle is that
{{$
  P(\tau_a \leq t) = 2P(B_t \geq a)
}}$
or equivalently
{{$
  P(B_t \geq a \mid \tau_a \leq t) = \frac{1}{2}.
}}$
