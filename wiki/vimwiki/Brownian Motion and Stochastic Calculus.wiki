= Brownian Motion and Stochastic Calculus =
== UChicago STAT 38510, Autumn 2023 ==

{{$
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}

\DeclareMathOperator{\Jac}{Jac}
\DeclareMathOperator{\Ker}{Ker}

\let\temp\phi
\let\phi\varphi
\let\varphi\temp

\newcommand{\pa}[1]{\left(#1\right)}
\newcommand{\bra}[1]{\left[#1\right]}
\newcommand{\cbra}[1]{\left\{#1\right\}}

\newcommand{\mat}[1]{\begin{matrix}#1\end{matrix}}
\newcommand{\pmat}[1]{\pa{\mat{#1}}}
\newcommand{\bmat}[1]{\bra{\mat{#1}}}

\newcommand{\pfrac}[2]{\pa{\frac{#1}{#2}}}
\newcommand{\bfrac}[2]{\bra{\frac{#1}{#2}}}
\newcommand{\psfrac}[2]{\pa{\sfrac{#1}{#2}}}
\newcommand{\bsfrac}[2]{\bra{\sfrac{#1}{#2}}}
}}$

=== Brownian Motion ===

As a style preference, I'm going to drop all the arguments that are from the probability space.

Fix a probability space $(\Omega, \mathcal F, P)$; we characterize the Brownian motion $\{B_t\}_{t \geq 0}$ via the follwing properties:
- *Independent Increments*: If $s < t$, the random variable $B_t - B_s$ is independent of $\sigma\{B_r: r \leq s\}$
- *Stationary Increments*: If $s < t$, then $B_t - B_s$ has the same distribution as $B_{t-s} - B_0$.
- *Continuity*: The map $t \mapsto B_t$ is almost surely continuous. 

*Theorem*: If a process satisfies the above, then there are $\mu, \sigma^2$ (respectively called the drift and the variance parameter, and $\sigma$ is named the volatility) such that there exist $B_t \sim N(\mu t, \sigma^2 t)$.

_Def_: A stochastic process $\{B_t\}_{t \geq 0}$ is called a (one dimensional) *Brownian motion* (or Wiener process) starting from the origin with drift $\mu$ and variance parameter $\sigma^2$ if $B_t = 0$ and the above three conditions are satisfied, with the imposition that 
{{$
B_t - B_s \sim N(\mu (t-s), \sigma^2 (t-s)).
}}$

*Prop*: If $B_t$ is a Brownian motion with $\mu = 0, \sigma^2 = 1$ (a so-called *standard Brownian motion*), then $Y_t = \sigma B_t + \mu t$ is a Brownian motion with parameters $\mu, \sigma^2$.

_Proof_: Obvious.

==== Construction ====

Pick a probability space $(\Omega, \mathcal F, P)$ that is rich enough to support a countable collection of independent standard normal variables. If you are particular, the unit interval with Lesbegue measure is sufficient here.

The strategy is as follows: we define $B_t$ for a countable dense set (in particular the dyadic rationals) of times using our precession of standard normals. then, we find some $t \mapsto B_t$ that agrees on the dense set and is uniformly continuous and then extend by continuity.

Set $D_n = \left\{ \frac{k}{2^n}, k = 0, 1, \dots, 2^n \right\}$ and $D = \bigcup_{n=0}^\infty D_n$; index our standard normals by $\{N_{q}\}_{q \in D}$, and set $B_0 = 0, B_1 = N_1$, and $B_{1/2} = \frac{B_1 - B_0}{2} + \frac{1}{2}N_{1/2}$. Just continue the same thing for every such dyadic, such that
{{$
\{B_{1/2^n} - B_0, B_{2/2^n} - B_{1/2^n}, \dots, B_1- B_{(2^n-1) / 2^n} \}
}}$
are all independent $N\left(0, 2^{-n}\right)$. 

*Theorem*: Almost surely, $t \mapsto B_t$, $t \in D$ is uniformly continuous.

_Proof_: Set $K_n = \sup \{ |B_s - B_t| \mid s,t \in D, |s - t| \leq 2^{-n}\}$. We just need to show that $K_n \to 0$ as $n \to \infty$. In fact, something even stronger is true: for $\alpha < \frac{1}{2}$, $\lim_{n \to \infty} 2^{\alpha n}K_n = 0$. Morally speaking, just think that each Brownian increment is about its standard deviation, which is $|t - s|^{1/2}$.

Technically, however, we proceed as follows: set
{{$
  Y_n = \max\{B_{1/2^n} - B_0, B_{2/2^n} - B_{1/2^n}, \dots, B_1- B_{(2^n-1) / 2^n} \}
}}$
and note that the union bound yields
{{$ 
\begin{align*}
  P(Y_n \geq x) &\leq \sum_{j=1}^{2^n} P(|B_{j/2^n} - B_{(j-1)/2^n}| \geq x) \\
      &= 2^nP(B_{1/2^n} \geq x) \\
      &= 2^{n+1}P(B_1 \geq 2^{n/2} x).
\end{align*}
}}$
If we choose $x_n$ such that $\sum_{n=1}^\infty 2^{n+1}P(B_1 \geq 2^{n/2}x_n) < \infty$, then by Borel-Cantelli shows that for sufficiently large $n$, $Y_n \leq x_n$ almost surely. Do any reasonable bound you like on the tail of the normal distribution and take a sufficiently large $x$ and call it a day. In particular, if you choose the easiest bound $P(N \geq x) \leq Ce^{-x^2/2}$, you can eventually get the bound:

*Prop*:
{{$
  \limsup_{n \to \infty} \frac{2^{n/2}}{\sqrt{n}}Y_n \leq \sqrt{2 \log 2}.
}}$

_Proof_: Look at the sum
{{$
  \sum_{n=1}^\infty P\left(Y_n > \sqrt{n} \cdot 2 ^{-n/2} \cdot \sqrt{2 \log 2 (1 + \epsilon)}\right)
}}$
and apply Borel-Cantelli. In particular, we have
{{$
\begin{align*}
  P(Y_n > x_n) &\leq \sum_{j=1^{2^n}} P(|B_{j/2^n} - B_{(j-1)/2^n}| > x_n) \\
  &= 2^{n+1}P(B_{1/2^n} > x_n) \\
  &= 2^{n+1}P\left(B_1 > \sqrt{n} \sqrt{2(\log 2 (1 + \epsilon)}\right) \\
  &\leq C 2^n e^{-\frac{\sqrt{2\log 2 n(1+\epsilon)^2}}{2}} \\
  &\leq C e^{-n\epsilon}.
\end{align*}
}}$

*Prop*: Set $K_n = \sup \{ |B_s - B_t| \mid s,t \in D, |s - t| \leq 2^{-n}\}$; then, there is $C$ such that with almost surely,
{{$
  \limsup_{n \to \infty} \frac{2^{n/2}}{\sqrt{n}}K_n \leq C.
}}$

_Proof_: It's easy to see that $K_n \leq 2 \sum_{j=n+1}^\infty Y_j$ (this is just the triangle inequality). Then for sufficiently large $n$, we get
{{$
  K_n \leq 2 \cdot 2 \sum_{j=n+1}^\infty 2^{-j/2}\sqrt{j}
}}$
with full probability, and so
{{$
  \sup_{\substack{s, t \in D \\ s < t}} \frac{|B_t - B_s|}{\sqrt{(t-s)|\log((t-s)^{-1})|}} < \infty.
}}$

Now we may set $B_t$ for $t \in [0, 1]$ by $B_t = \lim_{\substack{s \to t \\ s \in D}}B_s$, and check that this is in fact a genuine Brownian motion, which is not bad; and of course this construction can extend to $[0, \infty)$ easily as well.

==== Properties of Brownian Motion ====

_Def_: A function $f: [0, 1] -> \mathbb R$ is called *Hölder continuous* of order $\beta \geq 0$ if there is some $C < \infty$ such that for all $s, t$, $|f(t) - f(s)| \leq C|t-s|^\beta$. Futher, $f$ is *weakly Hölder continuous* of order $\beta$ if it is Hölder continuous of order $\alpha$ for all $\alpha < \beta$. In both cases, we will say Hölder-$\beta$ continuous for short.

*Prop*: Brownian motion paths are weakly Hölder-$\frac{1}{2}$ continuous.

_Proof_: Omitted.

*Theorem*: The function $t \mapsto B_t$ is nowhere differentiable almost surely.

_Proof_: Assume $|f'(t)| < K$; there exists $\delta > 0$ such that if $|s - t| \leq \delta$, $|f(t) - f(s)| \leq 2K|s-t|$; in particular there is an $N$ such that for all $n > N$, $|s - t| \leq n^{-1}, |r - t| \leq n^{-1}$, $|f(s) - f(r)| \leq 4Kn^{-1}$. Then, set 
{{$
  Z_{k, n} = \max \left\{ |B_{k/n} - B_{(k-1)/n}|, |B_{(k+1)/n} - B_{k/n}|, |B_{(k+2)/n} - B_{(k+1)/n}|\right\}
}}$
and
{{$
  Z_n = \min \{ Z_{k, n} \mid k = 1, \dots, n \}.
}}$

If $B$ is differentiable, then there is some $M$ such that $Z_n \leq Mn^{-1}$ for all $n$. Now set $E_M$ to be the event that $Z_n \leq Mn^{-1}$ for all sufficiently large; our theorem reduces to showing that $P(E_M)  = 0$ for all $M$. In fact, we will show that
{{$
  \lim_{n \to \infty} P(Z_n \leq Mn^{-1}) = 0.
}}$

Consider the union bound
{{$
\begin{align*}
  P(Z_n \leq Mn^{-1}) &\leq \sum_{j=1}^{n}P(Z(n,k) \leq Mn^{-1}) \\
  &\leq nP\left( \max \left\{ |B_{1/n}|, |B_{2/n} - B_{1/n}|, |B_{3/n} - B_{2/n}|\right\}
\right) \\
&\leq nP(|B_{1/n}| \leq Mn^{-1})^3 \\
&\leq nP(|B_1| \leq Mn^{-1/2})^3
\end{align*}
}}$
and just do literally the stupidest estimate you can, e.g. just look at the density and say that the probability is bounded by $2CMn^{-1/2}$, so that the above is sent to zero as $n \to \infty$.


==== Filtrations ====

_Def_: A filtration $\{ \mathcal F \}_{t \geq 0}$ is an incerasing collection of sub $\sigma$-algebras. Further, we put
{{$
  \mathcal F_{\infty} = \bigcup_{t \geq 0} \mathcal F_t.
}}$

_Def_: A stochastic process $\{X_t \}_{t \geq 0}$ is adapted to $\{ \mathcal F_t \}_{t \geq 0}$ if for each $t$, $X_t$ is $\mathcal F_t$-measurable.

_Def_: A process $\{ B_t \}_{t \geq 0}$ is a standard Brownian motion start at 0 w.r.t. $\{ \mathcal F_t \}_{t \geq 0}$ if
- $B_0 = 0$,
- $\{ B_t \}_{t \geq 0}$ is adapted to $\{ \mathcal F_t \}_{t \geq 0}$,
- if $s < t$ then $B_t - B_s$ is independent of $\mathcal F_s$,
- $B_t - B_s \sim N(0, t-s)$,
- and with probability 1 $t \mapsto B_t$ is continuous.

_Def_: A random variable $\tau$ taking values in $[0, \infty]$ is called a stopping time with respect to $\{ \mathcal F_t \}_{t \geq 0}$ if for every $t$, the event $\{\tau \leq t\} \in \mathcal F_t$.

_Examples_: The following are all stopping times:
- constants;
- $\tau = \inf\{ t \mid B_t \in V \}$ where $V$ is Borel;
- $\tau_1 \land \tau_2, \tau_1 \lor \tau_2$, where $\tau_1, \tau_2$ are both stopping times.

_Def_: If $\tau$ is a stopping time, then $\mathcal F_\tau$ is the $\sigma$-algebra corresponding to the collection of events $A$ such that for each $t$, $A \cap \{ \tau \leq t \} \in \mathcal F_t$.

==== The Markov Property of Brownian Motion ====

_Def_: For some stochastic process $\{X_t\}_{t \geq 0}$ (or any other indexed set) with filtration $\{F_t\}_{t \geq 0}$, $X_t$ has the *Markov property* if it saitisfies that
{{$
  E[f(X_t) \mid \mathcal F_s] = E[f(X_t) \mid \sigma(X_s)].
}}$

_Def_: In general, if $X_t$ is a stochastic process and $\tau$ is a stopping time, both adapted to $\{ \mathcal F_t \}_{t \geq 0}$ with $P(\tau < \infty) = 1$, then $X_t$ has the *strong Markov property* if $X_{\tau + t}$ is independent of $\mathcal F_{\tau}$.

*Prop*: Suppose $B_t$ is a Brownian motion and $\tau$ is a stopping time, both with respect to $\{ \mathcal F_t \}$, and assume $P(\tau < \infty) = 1$. Set
{{$
  Y_t = B_{\tau + t} - B_{\tau}.
}}$
Then $Y_t$  is a Brownian motion independent of $\mathcal F_t$, e.g. Brownian motion has the strong Markov property and the new process is also a Brownian motion.

_Proof_: You proceed by doing successive approximations.
- First, let $\tau$ take a finite amount of values, and use the normal Markov property.
- Then, approximate any $\tau$ by stopping times taking a finite amount of values, such as by
{{$
  \tau_n = \begin{cases}
    \frac{k}{2^n} & \frac{k - 1}{2^n} \leq \tau \leq \frac{k}{2^n} \leq n \\
    n & \tau > n
  \end{cases}
}}$
  for example.
- Take a limit by continuity.

In particular, the following is clear for Brownian motion:

*Prop*: If $\{B_t\}_{t \geq 0}$ is a Brownian motion, $t$ a fixed time, and $Y_s = B_{t+s} - B_t$, then $\{Y_s\}_{s \geq 0}$, is a BM and independent of $\mathcal F_t = \sigma\{B_s \mid s \leq t\}$.

*Theorem*: Set $B_t$ to a Brownian motion with drift zero; *the reflection principle* is that
{{$
  P\left(\max_{0 \leq s \leq t} B_s \geq a\right) = 2P(B_t \geq a).
}}$
Set $\tau_a = \min \{ s \mid B_s = a \}$; we also have
{{$
  P(\tau_a \leq t) = 2P(B_t \geq a)
}}$
or equivalently
{{$
  P(B_t \geq a \mid \tau_a \leq t) = \frac{1}{2}.
}}$

*Prop*: If $0 < r < s < \infty$,
{{$
  q(r, s) = P(B_t = 0 \text{ for some } r \leq t \leq s) = 1 - \frac{2}{\pi} \arctan\left(\sqrt{\frac{r}{s}}\right).
}}$

_Proof_: First, I claim that $q(r, s) = q(1, s/r)$ just by a change of variables, so we only need to compute $q(t) = q(1, t)$. Set $A = \{ B_s = 0 \text{ for some } 1 \leq s \leq 1 + t \}$, so that
{{$
\begin{align*}
  q(t) &= \frac{2}{\sqrt{2 \pi}}\int_0^\infty P(A \mid B_1 = x) e^{-x^2 / 2}dx.
\end{align*}
}}$
However, by the reflection principle, we have that
{{$
\begin{align*}
  P(A \mid B_1 = x) &= P\left(\max_{0 \leq s \leq t} B_s \geq x \right) \\
  &= P \left( \min_{0 \leq s \leq t} B_s \leq -x \right) \\
  &= 2P(B_t \geq x) = 2P\left(B_1 \geq \frac{x}{\sqrt{t}}\right)
\end{align*}
}}$
upon which we can just compute the integral.

*Corollary*: One dimensional standard Brownian motion is (pointwise) recurrent (that is, the zero set of Brownian motion is unbounded).

*Corollary*: Since $Y_t = t^{-1}B_{1/t}$ is a standard Brownian motion, this shows that for any $\epsilon > 0$, $Z_\epsilon = \{ t \mid B_t = 0, 0 \leq t \leq \epsilon \}$ has more elements that just $0$.

==== Martingales ====

_Def_: A process $\{ M_t \}_{t \geq 0}$ is a *supermartingale* (resp. *submartingale*) w.r.t. $\{ \mathcal F_t \}$ if
- $E[|M_t|] < \infty$,
- $M_t$ is $\{ \mathcal F_t \}$ adapted,
- and if $E[M_t \mid \mathcal F_s] \leq M_s$ (resp. $\geq M_s$) almost surely for $s \leq t$.
A process which is both a submartingale and supermartingale is just a martingale, it is continuous if $M_t$ is a continuous function of $t$ almost surely, and is square integrable (or simply $L^2$) if it has finite second moment for all $t$.

As an aside, I'm going to stop saying with probability 1 or almost surely because it's annoying!

*Prop*: Brownian motion (without drift) is an $L^2$ continuous martingale.

*Theorem (Kolmogorov Zero-One)*: Tail events of independent $\sigma$-algebras happen with probability 0 or 1.

_Proof_: Set $\mathcal F_n = \sigma(X_1, \dots, X_n)$, and $\mathcal T_n = \sigma(X_{n+1}, \dots)$, $\mathcal F_\infty = \bigcup_{n} \mathcal F_n$, and $\mathcal T_\infty = \bigcap_n \mathcal T_n$.

Then, one can see that if $A \in \mathcal F_\infty$ and $\epsilon > 0$, there is $n$ and $A_n \in \mathcal F_n$ such that $P(A_n \Delta A) < \epsilon$; even better, there exists $A_n$ independent of $A \in \mathcal T_\infty$ such that $P(A \Delta A_n) < \epsilon$, and so we conclude that $P(A) = P(A)P(A)$.

*Theorem (Blumenthal Zero-One)*: Let $B_t$ be a Brownian motion with the standard filtration, and set $\mathcal F_{0+} = \bigcap_{\epsilon > 0} \mathcal F_{\epsilon}$. Then, if $A \in \mathcal F_{0+}$, $P(A) = 0$ or $1$.
